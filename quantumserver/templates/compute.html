
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>QUANTUM COMPUTERS</title>

<style>
body {
  font-family: "Lato", sans-serif;
}

.sidenav {
  height: 100%;
  width: 0;
  position: fixed;
  z-index: 1;
  top: 0;
  left: 0;
  background-color: #111;
  overflow-x: hidden;
  transition: 0.5s;
  padding-top: 60px;
}

.sidenav a {
  padding: 8px 8px 8px 32px;
  text-decoration: none;
  font-size: 15px;
  color: #818181;
  display: block;
  transition: 0.3s;
}

.sidenav a:hover {
  color: #f1f1f1;
}

.sidenav .closebtn {
  position: absolute;
  top: 0;
  right: 25px;
  font-size: 36px;
  margin-left: 50px;
}

#main {
  transition: margin-left .5s;
  padding: 16px;
}

@media screen and (max-height: 450px) {
  .sidenav {padding-top: 15px;}
  .sidenav a {font-size: 18px;}
}
</style>


  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
   <link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='styles/stylesheet.css') }}">

    <nav class="navbar navbar-inverse">
        <div class="contianer-fluid ">
            <!--LOGO-->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#topNavBar">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

        </div>
    </nav>

</head>
<body>

<div id="mySidenav" class="sidenav">
  <a href="javascript:void(0)" class="closebtn" onclick="closeNav()">&times;</a>
  <a href="{{ url_for('intro') }}">Introduction</a>
  <a href="{{ url_for('net') }}">Networking</a>
  <a href="{{ url_for('crypto') }}">Cryptography</a>
  <a href="{{ url_for('teleport') }}">Quantum Teleportation</a>
  <a href="{{ url_for('ai') }}">AI in Quantum Computing</a>
  <a href="{{ url_for('compute') }}">Quantum Computers</a>
  <a href="{{ url_for('iot') }}">Iot with Quantum Computing</a>
  <a href="{{ url_for('material') }}">Material science in Quantum Computing</a>
  <a href="{{ url_for('tutorial') }}">Videos and Podcasts</a>
  <a href="{{ url_for('tools') }}">Tools for Quantum Programming</a>
</div>


<script>
function openNav() {
  document.getElementById("mySidenav").style.width = "250px";
  document.getElementById("main").style.marginLeft = "250px";
}

function closeNav() {
  document.getElementById("mySidenav").style.width = "0";
  document.getElementById("main").style.marginLeft= "0";
}
</script>


<div id="main">
  <span style="font-size:30px;cursor:pointer" onclick="openNav()">&#9776; Menu</span>

<h1>QUANTUM COMPUTER</h1>

<p align="RIGHT"><a href="{{ url_for('logout') }}" >Logout</a></p>

<h1><a href="http://www.iamwire.com/2019/06/need-promise-reality-quantum-computing/183286">[Article 1]: The Need, Promise, and Reality of Quantum Computing</a></h1>


<p>Despite giving us the most spectacular wave of technological innovation in human history, there are certain computational problems that the digital revolution still can’t seem to solve. Some of these problems could be holding back key scientific breakthroughs, and even the global economy. Although conventional computers have been doubling in power and processing speed nearly ever two years for decades, they still don’t seem to be getting any closer to solving these persistent problems. Want to know why? Ask any computer scientist, and they’ll probably give you the same answer: today’s digital, conventional computers are built on a classical, and very limited, model of computing. In the long run, to efficiently solve the world’s most persistent computing problems, we’re going to have to turn to an entirely new and more capable animal: the quantum computer.</p>
<p>Ultimately, the difference between a classical computer and a quantum computer is not like the difference between an old car and a new one. Rather, it’s like the difference between a horse and a hawk: while one can run, the other can fly. Classical computers and quantum computers are indeed that different. Here we take a good look at where the key difference lies, and take a deep dive into what makes quantum computers unique. However, what you won’t find here is a final explanation for how quantum computers ultimately work their magic. Because no one really knows.</p>
<h3>The hard limits of classical computing</h3>
<h4>Moore’s law, Shmore’s Law</h4>
<p>For several decades now, the sheer speed and computational power of conventional computers has been doubling every two years (and by some accounts just eighteen months). This is known as Moore’s law. Although the breakneck pace of progress may have finally begun to slow slightly, it’s still more or less true that the room-filling supercomputer of today is the budget laptop of tomorrow. So at this rate, it seems reasonable to assume that there is no computational task that a conventional computer couldn’t eventually tackle in the foreseeable future. Nonetheless, unless we’re talking trillions of years (and then some), that’s simply not a safe assumption when it comes to certain stubborn tasks.</p>
<h4>The conventional computer’s Achilles heel</h4>
<p>The fact is that a computational task such as quickly finding the prime factors for very large integers is probably out of reach for even the fastest conventional computers of the future. The reason behind this is that finding the prime factors of a number is a function that has exponential growth. What’s exponential growth? Well let’s dive into it because this is a very important piece for understanding why quantum computers have so much potential and why classical computers fall short.</p>
<h4>Quick introduction to exponential growth</h4>
<p>Some things grow at a consistent rate and somethings grow faster as the number of “things” you have also grows. When growth becomes more rapid (not constant) in relation to the growing total number, then it is exponential.
Exponential growth is extremely powerful. One of the most important features of exponential growth is that, while it starts off slowly, it can result in enormous quantities fairly quickly — often in a way that is shocking.
This definition can be a bit hard to get your head around without an example, so let’s dive into a quick story.
There is a legend in which a wise man, who was promised an award by a king, asks the ruler to reward him by placing one grain of rice on the first square of a chessboard, two grains on the second square, four grains on the third and so forth. Every square was to have double the number of grains as the previous square. The king granted his request but soon realized that the rice required to fill the chessboard was more than existed in the entire kingdom and would cost him all of his assets.</p>
<h4>Exponential Growth of Rice:</h4>

The number of grains on any square reflects the following rule, or formula:

In this formula, k is the number of the square and N is the number of grains of rice on that square.
    • If k = 1 (the first square), then N = 2⁰, which equals 1.
    • If k = 5 (the fifth square), then N = 2⁴, which equals 16.
<h4>This is exponential growth because the exponent, or power, increases as we go from square to square.</h4>
To conceptualize this further, I’ve included a graph of what exponential growth looks like in relation to the input quantity of an exponential function.

As you can see, the function starts relatively slow, but soon shoots up to numbers that no classical computer would be able to compute with large enough input sizes.
<h3>Real exponential functions have real consequences</h3>
<p>Okay, enough story telling. Let’s move on to real world exponential problems like the one we were talking about earlier. Prime Factorization.
Take the number 51. See how long it takes you to find the two unique prime numbers that you can multiply together to generate it. If you’re familiar with these kinds of problems, it probably only took you a few seconds to find that 3 and 17, both primes, generate 51. As it turns out, this seemingly simple process, lies at the heart of the digital economy and is the basis for our most secure types of encryption. The reason we use this technique in encryption is because as the numbers used in prime factorization get larger and larger, it becomes increasingly difficult for conventional computers to factor them. Once you reach a certain number of digits, you find that it would take even the fastest conventional computer months, years, centuries, millennia, or even countless eons to factor it.</p>


<p>With this idea in mind, even if computers continue to double in processing power every two years for the foreseeable future (and don’t bet on it), they will always struggle with prime factorization. Other equally stubborn problems at the heart of modern science and mathematics include certain molecular modeling and mathematical optimization problems which promise to crash any supercomputer that dares to come anywhere near them.
Below is a great illustration from IBM Research that shows the most complex molecule (F cluster) that we can simulate on our the worlds most powerful super computer. As you can see (in the bottom left of the image), the molecule is not very complex at all, and if we want to model more complex molecules to discover better drug treatments and understand our biology, then we will need a different approach!</p>

<h3>Enter the quantum computer</h3>
<p>Conventional computers are strictly digital, and rely purely on classical computing principles and properties. Quantum computers, on the other hand, are strictly quantum. Accordingly, they rely on quantum principles and properties — most importantly superposition and entanglement — that make all the difference in their almost miraculous capacity to solve seemingly insurmountable problems.
Superposition
To make sense out of the notion of superposition, let’s consider the simplest possible system: a two-state system. An ordinary, classical two-state system is like an On/Off switch that is always in one state (On) or another (Off). Yet a two-state quantum system is something else entirely. Of course, whenever you measure its state, you will find that it is indeed either on or off, just like a classical system. But between measurements, a quantum system can be in a superposition of both on and off states at the same time, no matter how counter-intuitive, and even supernatural, this may seem to us.</p>

<h4>Superposition</h4>
<p>Generally speaking, physicists maintain that it’s meaningless to talk about a quantum system’s state, such as its spin, prior to measurement. Some even argue that the very act of measuring a quantum system causes it to collapse from a murky state of uncertainty to the value (On or Off, Up or Down) that you measure. Although probably impossible to visualize, there’s no escaping the fact that this mysterious phenomenon is not only real, but gives rise to a new dimension of problem-solving power that paves the way for the quantum computer. Keep the idea of superposition in mind. We will come back to how this is used in quantum computing in a bit.
How superposition is even possible is beyond the scope of this article, but trust that it has been proven to be true. If you want to understand what gives rise to superposition then you are going to first need to understand the idea of Wave/Particle Duality.</p>
<h4>Entanglement</h4>
<p>Okay, on to the next property of quantum mechanics which we need to leverage to create a quantum computer.
It is known that once two quantum systems interact with one another, they become hopelessly entangled partners. From then on, the state of one system will give you precise information about the state of the other system, no matter how far the two are from one another. Seriously, the two systems can be light years apart and still give you precise and instantaneous information about each other. Let’s illustrate this with a concrete example as this caused even Einstein to puzzle about how this could be possible. (Einstein famously referred to this phenomenon as “Spooky action at a distance”)

Quantum Entanglement. Source: IBM Research
Suppose you have two electrons, A and B. Once you have them interact in just the right way, their spins will automatically get entangled. From then on, if A’s spin is Up, B’s spin will be Down, like two kids on a seesaw, except that this holds true even you take A and B to opposite ends of the Earth (or the galaxy, for that matter). Despite the thousands of miles (or light years) between them, it’s been proven that if you measure A to have spin Up, you will know instantly that B’s spin is Down. But wait: we’ve already learned that these systems don’t have precise values for states such as spin, but rather exist in a murky superposition, prior to measurement. So does our measuring A actually cause B to instantaneously collapse to the opposite value, even when the two are light years apart? If so, then we have yet another problem on our hands, because Einstein taught us that no causal influence, such as a light signal, between two systems can travel faster than the speed of light. So what gives? All told, we honestly don’t know. All we know is that quantum entanglement is real, and that you can leverage it to work wonders.</p>
<h3>The qubit</h3>
<p>The qubit plays the same role in quantum computing as the bit does in classical computing: its the fundamental unit of information. However, compared to a qubit, a bit is downright boring. Although both bits and qubits generate one of two states (a  or a 1) as the outcome of a computation, a qubit can simultaneously be in both  and 1 states prior to that outcome. If this sounds like quantum superposition, it is. Qubits are quantum systems par excellence.

Also Read:  What is Gene Editing with CRISPR?


Just as conventional computers are built bit by bit with transistors that are either On or Off, quantum computers are built qubit by qubit with electrons in spin-states that are either Up or Down (once measured, of course). And just as transistors in On/Off states are strung together to form the logic gates that perform classical computations in digital computers, electrons in Up/Down spin-states are strung together to form the quantum gates that perform quantum calculations in quantum computers. Yet stringing together individual electrons (while preserving their spin states) is far, far easier said than done.

Quantum Algorithms. Source: IBM Research</p>
<h3>Where are we today?</h3>
<p>While Intel is busy pumping out conventional chips with billions of transistors a piece, the world’s leading experimental computer scientists are still struggling to build a quantum computer “chip” with more than a handful of qubits. Just to give you a sense of how early we are in the history of quantum computing, it was a big deal when recently IBM unveiled the largest quantum computer in the world with an astonishing… wait for it… 50 qubits. Nonetheless, it’s a start, and if anything like Moore’s law applies to quantum computers, we should get into the hundreds in a few years, and the thousands in a few more. A billion? I wouldn’t hold your breath, but then again, you don’t need a billion qubits to outperform the daylights out of a conventional computer in some key categories, such as prime categorization, molecular modeling and a slew of optimization problems that no conventional computer can touch today.</p>
<h3>The quantum computers of 2018</h3>
<p>All the same, as of right now, nearly every quantum computer is a multi-million dollar borderline mad-scientist project that looks the part. You generally find them in R&D departments at large IT companies like IBM, or in the experimental physics wing of large research universities, like MIT. They have to be super-cooled to a hair above absolute zero (that’s colder than intergalactic space), and experimenters need to use microwaves of a precise frequency to communicate with each qubit in the computer individually. Needless to say, that doesn’t scale. But neither did the vacuum tubes of the earliest conventional computers, so let’s not judge this first generation too harshly.</p>
<h3>Roadblocks awaiting breakthroughs</h3>
<p>The primary reason that quantum computers haven’t gone mainstream yet is that the best minds and inventors in the world are still struggling with high error rates, and low numbers of qubits. As we address these two problems together, we will rapidly increase what IBM calls each computers’ “quantum volume,” a way of visualizing the sheer quantity of useful calculations a quantum computer can perform.


Quantum Volume. Source: IBM Research
In short, for quantum computing to take off and quantum-powered Macbooks to start flying off the shelves, we need far more qubits and far fewer mistakes. That’s going to take time, but at least we know what we’re aiming for, and what we’re up against.</p>
<h3>Myths vs explanations</h3>
<p>Although we know that quantum computers can easily do things that no conventional computer can dream of doing, we don’t really know how they do it. If this sounds surprising, given that the first-generation of quantum computers already exists, keep in mind the word quantum. We’ve been using quantum mechanics to solve problems for a century now, and we still don’t really know how it works. Quantum computing, as a member of the quantum family, is in the same boat. Michael Nielsen (who basically wrote the book on the subject), has argued convincingly that any explanation of quantum computing is destined to miss the mark. After all, according to Nielsen, if there were a straightforward explanation for how a quantum computer works (that is, something you could visualize), then it could be simulated on a conventional computer. But if it could be simulated on a conventional computer, then it couldn’t be an accurate model of a quantum computer, because a quantum computer by definition does what no conventional computer can do.</p>
<p>According to Nielsen, the most popular myth that pretends to explain quantum computation is called quantum parallelism. Because you’re going to hear the quantum parallelism story a lot, let’s look at it for a moment. The basic idea behind quantum parallelism is that quantum computers, unlike their conventional counterparts, explore the full spectrum of possible computational outcomes/solutions simultaneously (i.e. in a single operation), while digital computers must plod along, looking at each solution in sequence. According to Nielsen, this part of the quantum-parallelism story is roughly right. However, he sharply criticizes the rest of the story, which goes on to say that after surveying the full spectrum of solutions, quantum computers pick out the best one. Now that, according to Nielsen, is a myth. The truth, he insists, is that what quantum computers, like all quantum systems, are really doing behind the scenes is entirely out of our reach. We see the input, and the output, and what happens in between is sealed in mystery.</p>




<h1><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/quantum-computing-google-computer-lab-hartmut-neven-law-a8973951.html">[Article 2]: QUANTUM COMPUTING BREAKTHROUGH MEANS GOOGLE COULD BE VERY CLOSE TO REVEALING REVOLUTIONARY MACHINE</a></h1>
<p>Google is close to realising a practical quantum computer for the first time after making a major discovery with the revolutionary form of computing.
Hartmut Neven, director of Google’s Quantum Artificial Intelligence Lab, revealed to Quanta magazine that his lab’s most advanced quantum processor was improving at a rate far beyond what they had previously thought possible.
The revelation means the tech giant may be just months away from achieving what is known as quantum supremacy, whereby quantum computers are able to solve problems that classical computers practically cannot.</p>
<p>Quantum computers work by replacing traditional bits – the ‘ones’ and ‘zeros’ used in digital communications – with quantum bits, or qubits.
The quantum properties of qubits mean they exist in a state of superposition, meaning the act as both zeros and ones at the same time.
This unusual phenomenon allows quantum computers to be vastly more powerful than traditional computers and means they could potentially solve computing challenges far beyond the reach of the world’s most powerful supercomputers. It was previously thought that quantum computers were able to make calculations exponentially faster than traditional computers, whereby every qubit added improves the machine’s processing power at an exponential rate.</p>
<p>But computer scientists at Google’s quantum computing lab observed that its systems were gaining power at a “doubly exponential” rate when compared to classical computers.
Quanta magazine described it: “Even exponential growth is pretty fast. It means that some quantity grows by powers of 2: 21, 22, 23, 24. The first few increases might not be that noticeable, but subsequent jumps are massive. Doubly exponential growth is far more dramatic. Instead of increasing by powers of 2, quantities grow by powers of powers of 2: 221,222,222,224.” This rate of development is so unfathomably fast that there is nothing that grows as quickly in the natural world to make a comparison to. </p>
<p>“It looks like nothing is happening, nothing is happening, and then whoops, suddenly you’re in a different world,” the lab’s director Hartmut Neven told Quanta Magazine. “That’s what we’re experiencing here.”</p>


<h1>Researchers explore architectural design of quantum computers</h1>



<p>A recent study led by Princeton University researchers, in collaboration with University of Maryland and IBM, explored the architectural design of quantum computers (QC). In a paper presented at the 2019 ACM/IEEE International Symposium on Computer Architecture, the researchers performed the largest real-system evaluation of quantum computers to date, using seven quantum computers from IBM, Rigetti and the University of Maryland. The researchers developed new software to compile from QC applications to hardwareprototypes; on error-prone early-stage QC hardware, this compiler delivers up to 28 times improvement in program correctness rates compared to industry compilers. The study stresses the importance of careful instruction set design, rich connectivity topologies and the need to co-design applications and hardware to achieve the best performance from fledgling QC systems. Widely different quantum computing technologies</p>
<p>Quantum computing is a fundamentally new paradigm of computation with promising applications in drug design, fertilizer design, artificial intelligence and secure information processing, among other things. From its inception in the 1980s as a purely theoretical endeavor, quantum computing has now progressed to the point that small prototype systems are available for experiments. Companies such as IBM and Rigetti now offer free access to their five- to 16-qubit systems over the cloud. These systems can be programmed using sequences of instructions, also known as operations or gates.
Analogous to the early days of classical computing involving systems built with vacuum tubes relay circuits or transistors, QC systems today can be built out of several hardware technologies. Front-runner technologies include superconducting qubits and the trapped ion qubits, with other candidate technologies also of considerable interest. However, unlike classical binary computers, QC technologies are so different that even the fundamental gate operations that can be performed on a single qubit differ widely. Selecting the most appropriate gate operations to be exposed for software use is an important QC design decision.</p>
<p>Current QC systems also differ in terms of the reliability of operations between pairs of qubits. For example, in superconducting qubits such as those from IBM and Rigetti, the qubits are printed on a 2-D wafer using a method similar to classical processor fabrication. In these systems, inter-qubit operations are permitted only between qubits that are close to each other and connected by special wires. This fabrication approach imposes limitations in how different qubits can communicate, namely allowing each qubit in the system to interact directly with only a few other near-neighbor qubits. In contrast, for the trapped ion qubits in UMD, inter-qubit operations are accomplished using the vibrational motion of a chain of ions. Because this approach does not use physical connections in the form of wires, it allows inter-qubit operations between any pair of qubits in the system. This more expansive communication model can be helpful to some QC algorithms.
A third characteristic of note is that in all these candidate technologies, the quantum state is very hard to manipulate precisely. This leads to operational error rates. In addition, the magnitude of these errors varies significantly, both across the qubits in the system and across time. As a result, these large noise variations change the reliability of the operations by up to a factor of 10. Since QC algorithms chain several of these operations together, per-operation error rates compound to make it hard for the program to get the right answer overall. Architecture for quantum computers
The dramatic differences among different QC implementations has spurred researchers to design programming interfaces that shield the programmer from the implementation details and error rates of the qubits. Such an interface, commonly known as instruction set architecture (ISA), serves as a cornerstone of modern computing systems.</p>
<p>The ISA includes a set of instructions that can be executed on the hardware and serves as a contract between the hardware implementation and software. As long as the program uses operations permitted by the ISA, it can be run without modifications on any hardware, which also implements the same ISA, irrespective of any differences among the hardware implementations.
QC vendors make a number of design decisions about the ISA and the connectivity of the qubits. Each vendor chooses to provide a set of software-visible gates that mask the particular details of the gate implementations. These gates are typically not the same as the fundamental operations, and are commonly chosen to be operations that are frequently used by quantum algorithm designers and programmers.</p>
<p>"Which gates should a vendor choose to expose to hardware? Should we abstract these gates in a common ISA across vendors or tailor them to the underlying device characteristics?" asks Prakash Murali, a graduate student at Princeton and an author on the study. Similarly, the choice of qubit connectivity, although influenced by the hardware technology, determines what inter-qubit operations a program can use. "How should the vendor interconnect their qubits? How does the interplay of variable noise rates and connectivity influence programs?" says Murali.
Design insights for quantum computer architecture</p>
<p>To answer these design questions, the researchers evaluated the architecture of seven systems from three vendors, IBM, Rigetti and UMD, with different connectivity topologies, spanning two hardware qubit technologies. Since quantum computers are noisy, it is standard practice in the field to run programs several thousand times and report the answer which occurs most frequently as correct answer. To increase the likelihood of correct runs, this work developed TriQ, a multi-vendor optimizing compiler that outperforms vendor compilers by significant margins, despite cross-platform applicability.</p>
<p>Using TriQ, the researchers showed that the architectural design choices of a system can significantly influence the correctness rate of program runs, underscoring the importance of making these design choices with program requirements in mind. They observed that the vendor's choice for the software-visible gate set can influence both the number of operations required to run a program and the correctness rate. When the vendor exposes the native or fundamental operations, TriQ can significantly reduce the number of native operations required to perform a set of program instructions, and increase the correctness rate. This suggests that on quantum computers, it is premature to shield all knowledge of the native instructions through a device or vendor-independent ISA in a manner similar to classical systems.</p>
<p>"We also found that the match between the application's communication requirements and the hardware connectivity topology is crucial. When the hardware can support an application with only a small number of communication operations, the application usually has higher chances of executing correctly. When there is a mismatch, and a lot of communication operations are required, application correctness rates suffer," said Murali.</p>
<p>With its open-source software tools now available on github, the work in this paper has the potential to offer significant real-world improvements in QC software compilation, while also offering the opportunity for broader insights on the design approaches most effective for QC hardware.</p>

<h1><a href="https://venturebeat.com/2019/06/26/d-waves-open-source-platform-for-quantum-classical-hybrid-apps-hits-general-availability/">[Article 3]: D-Wave’s open source platform for quantum-classical hybrid apps hits general availability</a></h1>



<p>D-Wave today announced the general availability of D-Wave Hybrid, its open source hybrid workflow platform for building and running quantum-classical hybrid applications. You can download D-Wave Hybrid, which is part of the company’s Ocean SDK, from GitHub.
Binary digits (bits) are the basic units of information in classical computing, while quantum bits (qubits) make up quantum computing. Bits are always in a state of 0 or 1, while qubits can be in a state of 0, 1, or a superposition of the two. Quantum computing leverages qubits to perform computations that would be much more difficult for a classical computer. Hybrid computing lets classical and quantum systems be utilized in parallel. (D-Wave’s quantum computers use quantum annealing.</p>

<p>D-Wave today announced the general availability of D-Wave Hybrid, its open source hybrid workflow platform for building and running quantum-classical hybrid applications. You can download D-Wave Hybrid, which is part of the company’s Ocean SDK, from GitHub.
Binary digits (bits) are the basic units of information in classical computing, while quantum bits (qubits) make up quantum computing. Bits are always in a state of 0 or 1, while qubits can be in a state of 0, 1, or a superposition of the two. Quantum computing leverages qubits to perform computations that would be much more difficult for a classical computer. Hybrid computing lets classical and quantum systems be utilized in parallel. (D-Wave’s quantum computers use quantum annealing.)</p>
<p>D-Wave first released Hybrid as a developer preview in December. The framework helps developers gain insight into system performance, optimize code across systems, and more easily develop quantum hybrid applications. It includes:</p>
<ul>
  <li>Hybrid workflow control: Development of hybrid applications that can run across classical, the D-Wave 2000Q, and future quantum systems.</li>
  <li>Modular approach: Logic to simplify distribution of classical and quantum tasks. Developers can interrupt and synchronize across the systems and draw maximum computing power out of each.</li>
  <li>Problem deconstruction: Break down large problems that are bigger than the quantum processing unit (QPU) into parts.</li>
  <li>Familiar coding environment: Python-based framework and documentation includes examples for getting started without knowledge of quantum mechanics.</li>
  <li>Flexibility: Example hybrid workflows, allowing developers to explore which workflows are best for the problem they are solving.</li>
  <li>Real-time access to D-Wave 2000Q and Quantum Application Environment (QAE) resources, including learning tools, community, and technical forums.</li>
</ul>
<h4>Hybrid strategy</h4>
<p>“Prior to the general availability of D-Wave Hybrid, building hybrid algorithms was much more ‘from scratch’ by each user,” Murray Thom, D-Wave’s VP of software and cloud services, told VentureBeat. “With today’s Hybrid availability, we’ve provided an on-board for developers to more quickly get started prototyping their hybrid applications.”
D-Wave today also laid out its software strategy moving forward: to build and optimize for hybrid today. “Three Truths and the Advent of Hybrid Quantum Computing” details how developers, researchers, and forward-thinking businesses can solve complex problems using both classical and quantum systems.</p>

<p>D-Wave wants to offer a hybrid platform that lets developers leverage the most appropriate computing resources for each part of their application, without worrying about the size and topology of the QPU. The hybrid platform also provides the flexibility for developers to experiment with different strategies for hybridizing their applications.
D-Wave also argues that its customers don’t care which system is running in the background. All that matters is that the solution is more effective and more efficient.
In short, D-Wave believes that quantum computing will always require classical systems. The hope is that pushing for hybrid will accelerate the progress of quantum computers as connectivity and size increases, while noise decreases. In February, D-Wave previewed its next-generation quantum computing platform, coming in 2020.</p>

<h1><a href="https://www.pbs.org/wgbh/nova/video/six-ways-quantum-computers-could-change-the-world/">[Article 4]: Six Ways Quantum Computers Could Change the World</a></h1>
<p>
<ul>
Onscreen: A new type of supercomputer is on the horizon. Quantum computers are able to solve complex problems quickly, thanks to quantum physics.
<li>Rob Schoelkopf: A quantum computer is a new device for processing information that employs the unique aspects of the quantum world.</li>
Onscreen: Ordinary computers store information in 0s and 1s, or bits.Quantum computers store information in qubits which can exist as both 0s and 1s at once.
<li>Rob Schoelkopf: A quantum computer can be uniquely suited for doing certain computational tasks that are otherwise intractable today. anything where there is a needle-in-a-haystack type problem where you are searching through a very large number of combinations, a quantum computer can explore them, in a properly designed algorithm, all at the same time. “</li>
<li>Marissa Giustina: I think quantum computing will change the way we do research. It will give us a different tool for asking questions about nature and that’s really exciting.</li>
Onscreen: To outperform traditional computers, a quantum computer needs many qubits to work together. And that’s no easy task.
<li>Marissa Giustina: One qubit does not a quantum computer make. There is a big difference between one qubit and a large array of qubits that all work together and can be controlled coherently. It can be that adding a few more qubits affects your system in more complicated ways that you didn’t anticipate.</li>
Onscreen: Here are six ways quantum computing would change the world.
<li>1. Enhance artificially intelligent systems</li>
Quantum computers have the potential to create really robust AI algorithms
<li>2. Discover new materials</li>
The search for a high temperature superconductors has been the holy grail of material science. Quantum computers could help make this a reality, and vastly improve the energy grid and transportation system.
<li>Rob Schoelkopf: Giving chemists for example insight new ways to synthesize molecules, or material scientists hints about how they could make a better material for photocells or better batteries – these are the things we are excited about and looking forward to in the next few years.</li>
Onscreen: 
<li>3. Improve roads, and travel</li>
Quantum computers could predict high traffic hours. Leading to advances in navigation applications and traffic signal coordination.
<li>4. Revolutionize cryptography</li>
A method called quantum encryption has the potential to make messages exponentially more secure. But it also might make current methods of encryption obsolete.
<li>5. Better predict weather</li>
Better predictions could mean more time to evacuate ahead of catastrophic weather.
<li>6. Create more effective drugs</li>
Quantum computing could accelerate the rate of medical breakthroughs.
</ul>

<p>Quantum computing is still a very young field, but it could fundamentally change almost every industry.
<li>Schoelkopf: We’re on the dawn of creating a whole new industry or paradigm for information so this is very exciting.</li>

<h1><a href="https://interestingengineering.com/googles-quantum-processor-may-achieve-quantum-supremacy-in-months">[Article 5]: Google's Quantum Processor May Achieve Quantum Supremacy in Months</a></h1>
Moore's Law famously held that computer processor power would double about every two years, but now, Neven's Law appears to show quantum computing's explosive, 'doubly exponential' growth.
While I said several months ago that we'd find a way to bring Moore's Law back, I didn't expect it to go down like this. In a new report in Quanta Magazine by Kevin Hartnett, Hartmut Neven, the director of Google's Quantum Artificial Intelligence Lab, reveals that the growth in power with each new improvement to Google's best quantum processor is unlike anything found in nature. It's growing at not just an exponential rate, like in Moore's Law, but at a doubly-exponential rate, meaning we may be mere months away from the beginning of the practical quantum computing era.
Google's Hartmut Neven is Telling Us to Get Ready
Hartnett's piece should be a major wake-up call for the world. As we've plodded along, thinking that tomorrow would be more or less like today, something extraordinary appears to be taking place at Google's Quantum AI labs in Santa Barbara, California. In December 2018, Neven and his team began running a calculation on the company's best quantum processor when they began to see something unbelievable.</p>

<p>"They were able to reproduce the [quantum processor's] computation using a regular laptop," Hartnett writes. "Then in January, they ran the same test on an improved version of the quantum chip. This time they had to use a powerful desktop computer to simulate the result. By February, there were no longer any classical computers in the building that could simulate their quantum counterparts. The researchers had to request time on Google’s enormous server network to do that.
“Somewhere in February I had to make calls to say, ‘Hey, we need more quota,’" Nevens told Hartnett. “We were running jobs comprised of a million processors.”</p>

<p>Google's top-performing quantum processor was doing something that has no obvious parallels in nature. "Doubly exponential growth," Hartnett writes, "is so singular that it’s hard to find examples of it in the real world. The rate of progress in quantum computing may be the first."
The unparalleled acceleration of quantum computing speeds Neven first identified started being called Neven's Law by Google researchers in a not-so-subtle reference to classical computing's Moore's Law, but with a difference. They are of a kind, but what is happening over at Google is not simply the return of Moore's Law for the quantum era; Neven's law is showing us that we may be about to plunge into an entirely alien world in only a few months.</p>
<p>Why Moore's Law Continues to Matter Even After It's Demise</p>
<p>For the past decade, computer scientists and engineers have been anticipating the seemingly abrupt end of progress. Moore's Law, a rough guideline that says a silicon transistor can be reduced in size by about half about every two years, has been functionally dead for at lease a couple of years now.
While it lived, however, it was able to cram more and more transistors onto chips of various sizes, first empowering mainframes, then servers, then personal computers, and now mobile devices. Every couple of years, each new device wasn't just an improvement; there would be revolutionary technological changes as often as twice or three times in a single decade.
The doubling of processing power in each generation of computer chips every two years and the consequence of that rate of growth is the leap made by going from punch card computers calculating the flight paths of Apollo astronauts heading to the moon to the birth and maturing of the Internet, blazing fast computers in our pockets, and neural networks that can run the entire civil service infrastructure of cities in China in less than 50 years.</p>
<p>The technological leap humanity made with the silicon transistor was the single greatest innovation in human history. No other discovery or invention, not even fire, has transformed so much, so fast in our human experience--and we've known for at least a decade that this pace of change could not go on forever. As transistors are reduced to just seven nanometers long, engineers are fighting to keep an electric charge flowing in channels whose walls are only atoms thick.
Make the transistor any smaller, and the electric current that powers the processor's calculations and logic simply jumps the channel or leaks out of the component after atoms meant to contain the flow of electrons are disrupted over time.</p>
<p>As more transistors begin to fail and leak their electrons into other components, those too wear down faster and experience higher rates of error, inhibiting the performance of the processor as a whole until the whole thing becomes a useless, leaky sieve of electrons.
Since engineers cannot stabilize the components of the processor if they go any smaller, the silicon chip has reached its physical limit--bringing an end to Moore's Law and with it the expectation that two years from now computers will be twice as fast as they are today.
We don't like this at all, to say the least. We can see the technological potential peaking up on the horizon; to come so close and be restrained by physical laws is the kind of thing that first drove us to innovate in the first place.</p>
<p>So what do you do if you can't make a faster computer using atomic scales? Scientists and engineers inevitably took the next step and looked for something smaller than the atom for an answer, to quantum mechanics.</p>

<h2> The Quantum World</h2>
<p>The quantum world, however, is not at all like the classical world. Exotic subatomic particles behave in ways that are hard to accept. They can blow right through foundational laws of physics without missing a step, as quantum entanglement does when paired particles communicate instantaneously with each other even if they are on opposite sides of the universe.
Schroedinger himself, one of the principal discoverers of the quantum mechanics, proposed his famous thought experiment about a cat in a box which is both alive and dead at the same time to demonstrate how absolutely absurd his theories were becoming. He couldn't believe that it was exactly as it appeared.
As maddening as it was, the unavoidable fact is that Schroedinger's cat is indeed both alive and dead at the same time and will remain so until an observer opens the box to check on it; that is the moment the universe has to decide, in purely random fashion, what the ultimate state of the cat actually is.
Not only has this superposition of Schroedinger's cat been proven in practice, but the superposition of particles is also where the power of a quantum computer comes from.
By operating on a particle in superposition--called a quantum bit, or qubit--vastly more data can be contained in quantum memory with far fewer bits than in classical computers, and operations on a qubitapply to all possible values that qubit takes on. When these qubits are paired with other interdependent qubits--can perform vastly more complicated logic operations in significantly less time.
This potential for drastically improved processing speed over classical processors is what is driving so much of the hype around quantum computing right now. It's our way of keeping the current rate of progress going, no longer confined to the water's edge by the end of Moore's Law.
How Quantum Computing is Guaranteed to Upend Our Technology
So how powerful is quantum computing exactly then? What does this speed translate into, in real terms? For a while, the answer was nothing. It was actually a ridiculous idea that no one really took seriously.</p>
<p>Proposed in various ways over the years in academic papers since the 1970s, it popped up every now and again but not only was it impossible to imagine such a system in practice; such a machine wouldn't serve any real purpose to justify even investing money to investigate it. Then, in 1994, mathematician Peter Shor published a paper that changed everything.
Shor created an algorithm that cracked open a brutally intractable math problem that is the basis for modern RSA cryptography, the problem of prime factorization of integers. Prime factorizing a several thousand digit long integer is just not something a classical computer can do efficiently, no matter how many processors you throw at it; the necessary algorithms either aren't known or don't exist.</p>
<p>Even as modern computers became more powerful and were able to use raw processing power to crack earlier 256-bit, 512-bit, and even higher bit-count encryption keys, all one would need to do is multiply the bit-count used for your key by two and your new scheme was literally exponentially stronger than the one that just got cracked.
A classical computer doesn't get exponentially better at solving these problems as the numbers involved increase. This limitation, known as time complexity, eventually put some things beyond classical computers capacity to ever really solve. Lengthening RSA encryption-keys can very quickly begin to add millions, billions, and even trillions of years to the time needed to crack the encryption key using a classical computer.</p>
<p>What Shor showed was that using the superposition of qubits would allow you to solve the factorization problem significantly faster. It might still take a long time to break open the toughest RSA encryption, but a trillion-trillion-year-problem was made into a 2-to-5-year problem with a quantum computer--and onlywith a quantum computer.
If Neven's Law Bears Out, Quantum Computing Will Be Here in Under a Year
People finally took notice after Shor published his paper and realized this was something completely different than classical computing, and potentially orders of magnitude more powerful.
People started to see the potential, but in the 20+ years since Shor's algorithm first appeared, running that algorithm and maybe a few other quantum algorithms published in the years since remain the only reason why we'd ever need a quantum computer in the first place. We have been told that it will change everything, and we have waited as very, very little seems to be happening in reality.
Even many computer science professionals, including Ph.D.s and industry veterans who know the science behind it all, have expressed skepticism that quantum computing will deliver its at-times unbelievable promise. That may be changing, however, after Neven went public in May about the incredible growth of Google's quantum processors at Google's Quantum Spring Symposium and introduced the world to the "Law" that bears his name.</p>
<p>He revealed that what he and the rest of Google's quantum computing team were looking at was the "doubly exponential" growth of quantum computing power relative to classical computing: "it looks like nothing is happening, nothing is happening, and then whoops, suddenly you’re in a different world," he said. "That’s what we’re experiencing here.”</p>
<p>What Does Doubly Exponential Growth Actually Mean? </p>
<p>According to Neven, there are two factors that combine to produce this incredible rate of growth Google is seeing in its quantum computer chips.
The first simply being the natural exponential advantage that quantum computing has over a classical computer. Where classical bits can only be in one state at any given time, 1 or 0, a qubit in superposition is both 1 and 0. This means that a qubit becomes exponentially more efficient in terms of representing and processing data for each additional qubit added. For any given number of qubits n in a quantum processor, they do the same work or hold the same amount of data as 2n classical bits. 2 qubits equals 4 bits, 4 qubitsequals 16 bits, 16 qubits equals 65, 536 bits, and so on.
The second is more directly related to the improvements that Google is making to its quantum processors. According to Neven, Google is seeing their best quantum processors improve at an exponential rate, something that IBM has also seen with its IBM Q System One. Taken together, Neven says, you end up with a doubly exponential rate of growth of quantum computing relative to classical computing.
What does doubly exponential growth look like? The classic exponential growth function when dealing with bits is obviously doubling, a function defined as 2n in binary systems. How do you double doubling? Simply replace the n in the doubling function with another doubling function, or 22n.</p>

<p>Since Moore's Law is a doubling function, we can represent Moore's Law like this, where n represents a two year interval:</p>
   n     Classical computing power (2n) 
* 1      2
* 2     4
* 3     8
* 4     16
* 5     32 
* 6     64
* 7     128
* 8     256
* 9     512
* 10   1024
<p>So what does Neven's Law look like? It would look something like this, where n equals each new improvement to Google's quantum processor:</p>
<ul>
 <li>n      2n       2(2n)         Quantum Computing Power Relative to Classical Computing Power</li>
 <li>1       2         22            4</li>
 <li>2      4         24            16</li>
 <li>3      8         28            256</li>
 <li>4      16       216           65,536</li>
 <li>5      32       232          4,294,967,296</li>
 <li>6      64       264          18,446,744,073,709,551,616</li>
 <li>7      128      2128         3.4028236692093846346337460743177e+38</li>
 <li>8      256     2256         1.1579208923731619542357098500869e+77</li>
 <li>9      512      2512         1.3407807929942597099574024998206e+154</li>
 <li>10    1024    21024       1.797693134862315907729305190789e+308</li>
</ul>
<p>After the list goes above 6, the numbers start becoming so large and abstracted you lose the sense of the gulf between where Google is and where it will be at the next step.
In the case of Moore's Law, it started out in the 1970s as doubling every year, before being revised up to about every two years. According to Neven, Google is exponentially increasing the power of its processors on a monthly to semi-monthly basis. If December 2018 is the 1 on this list, when Neven first began his calculations, then we are already between 5 and 7.</p>
<p>In December 2019, only six months from now, the power of Google's quantum computing processor might be anywhere from 24096 times to 28192 times as powerful as it was at the start of the year. According to Neven's telling, by February--only three months after they began their tests, so 3 on our list--, there were no longer any classical computers in the building that could recreate the results of Google's quantum computer's calculations, which a laptop had been doing just two months earlier.</p>
<p>Neven said that as a result, Google is preparing to reach quantum supremacy--the point where quantum computers start to outperform supercomputers simulating quantum algorithms--in a only a matter of months, not years: “We often say we think we will achieve it in 2019. The writing is on the wall.”</p>
<p>Skepticism is Warranted, to a Point
It's important to stress that this growth in power is relative to the power of a classical computer, not an absolute measure, and that the starting point for quantum computing not that long ago would be comparable to the UNIVAC vacuum tube-era computers from the 1940s and 1950s.
Much of the core theoretical-computer science of quantum computing is still being written and debated, and there are those who have their doubts about whether "doubly exponential" growth relative to classical computing is truly happening.
After all, Moore's Law may be done for, but classical computing isn't dead, it continues to improve to this day and will continue to do so as new algorithms are developed that improve the efficiency of classical computers.</p>
<p>Still, others say that it isn't enough to just downplay or dispute the rapid progress claimed by Google for its quantum processors. IBM may be more modest in their predictions about quantum supremacy, but they're confident they can achieve it in about three years. Five years ago, many thought we wouldn't see a quantum computer until 2025 or even as late as 2030 and beyond.
Now, it's looking like we may even see the real deal by Christmas, and there's no reason to think that the power of quantum computers won't continue to increase even further once either Google or IBM or even someone else achieves true quantum supremacy.</p>
What makes a great qubit? Diamonds and ions could hold the answer

An ion-trapping device from Sandia National Labs | Photo credit: C. Suplee and E. Edwards/Joint Quantum Institute

<p>In the world of quantum computing, diamonds might be an engineer’s best friend.
That’s because a fabled, super-pure type of gem mined from the Ural Mountains has quantum properties that could provide a promising model for a stable, scalable quantum computer.
For several decades, scientists have been working on applying the strange laws of quantum mechanics—which govern the subatomic world—to the field of computing. So-called quantum computers, they say, could theoretically solve many problems much faster than any classical computer could. That’s because the basic unit of quantum information (a qubit) is fundamentally different in nature from the basic unit of classical information (a bit).</p>

<p>A qubit is sort of like a person—it contains multitudes. Whereas a bit has a definite value of 0 or 1, a qubit can exist in two states (both 0 and 1) simultaneously. Quantum particles spend their lives in a superposition of states: sometimes 0 and a hint of 1, other times possibly 0 but more likely 1, and so on. When we observe a qubit, or subject it to the influences of the macroscopic world, that mosaic of states “collapses” into a single reality—much like when you interact with or observe a friend, you’re only seeing a snapshot of her personality at any given moment. Qubits’ complexity makes them stronger. Together with lots of other qubits, they’re able to assess all possible solutions </p>

<p>Quantum computing, then, is extremely exciting. This sophisticated technology could enhance privacy and security, help build more accurate clocks, improve machine learning, and even assist in the creation of new materials. And yet, a major barrier to realizing these advances is qubits’ strength. Along with superposition, “entanglement,” which allows two particles to exert an instantaneous influence on each other, is a key element of quantum computing. But scientists haven’t figured out how to entangle a huge bundle of qubits at once, nor how to increase their coherence times (the amount of time a particle is locked in a state of superposition before collapsing into a single state). Until engineers can transcend these limitations, we likely won’t see a large-scale quantum computer available for commercial use.</p>
<p>“I think it’s going to be just a few years until we see quantum computers that are offering real value on the first initial [math] problem sets, which will maybe be more scientific in nature,” says Robert Schoelkopf, a professor of physics at Yale University and a director of the Yale Quantum Institute. “But then I think we’ll rapidly see an expansion of the kinds of problems these quantum computers can address as we get better and better at engineering them.”</p>
<p>To get there, Schoelkopf and others are trying to make qubits into Olympic athletes: strong, resilient, and cooperative in team settings. And they’re looking to the tiniest and purest objects in the universe for the most elite qubit prototypes, since any Schrödinger’s cat-like object that both is and isn’t in a particular state could be the basis for a viable qubit. Three major contenders for the gold medal in qubit-ing are nitrogen-vacancy (NV) centers in diamond lattices, trapped ions, and superconducting qubits—but they all have distinct advantages and disadvantages.
Qubits need to be isolated from their surrounding environment</p>
<p>The most amateur qubit, the isolated single atom, obeys one of the most important laws of quantum computing: that qubits need to be completely isolated from the outside world. This is the most basic form a qubit can take. When separated from the outside world in a vacuum, its energy states (sometimes called spin states) store quantum information in a way that is durable and long-lasting.
Too many interactions with the surrounding environment can deflate the integrity of the quantum system and cause it to collapse into a single reality, a process called decoherence. This is why experimentalists cool most quantum computers to very low temperatures: large copper-colored cylinders refrigerate so-called superconducting qubits (which companies like IBM and Google are investing in) so that they move more slowly and are less suited to interact with undesirable particles. Laser beams can also cool single atoms until they are nearly at rest by transferring momentum from the atom to the scattered laser light.</p>
<p>The problem with the isolated single atom, though, is that its neutral charge means it’s harder to entangle them because they’re not as reactive. And to build real quantum machines capable of super-powered mathematical acrobatics, engineers need to entangle lots of qubits.
“There’s a fundamental tension of trying to keep the isolation from the outside world while simultaneously controlling the quantum bits and making them talk to each other,” Schoelkopf says.
Qubits need to communicate effectively with other qubits</p>
<p>Take away one electron from a neutral atom and you have an ion—a positively charged particle. Ions interact strongly with one another, but scientists have played around with “trapping” ions in an electromagnetic field and then deep-freezing them with lasers to form a crystal of ions. Additional lasers can help nudge the crystals’ ions into a state of entanglement, and multiple crystals linked together subsequently become the building blocks of a larger quantum network.
The benefit of trapped-ion systems is that the ions are inherently going to affect one another. “When you physically shake one of them, all of the other ions feel it,” says Michael Goldman, a postdoctoral researcher at the Joint Quantum Institute in Maryland. Systems like this that are scalable (meaning engineers can make them bigger) and malleable are promising models for quantum computers—they can do very fast operations, Schoelkopf says.</p>

<p>Segmented razor blade trap used to trap ions | Photo credit: E. Edwards/Joint Quantum Institute
Trapped-ion qubits can do a lot. They’re easily entangled, plus scientists can turn that interactivity on and off easily so that individual qubits don’t engage with unwanted thermal fluctuations, or heat that would cause the system to decohere. And they’re becoming popular enough that companies like IonQ and Honeywell are investing in technologies that incorporate them.
“Nature makes [the ions] identical,” Goldman says. “They’re clean and have a long coherence time. As a system, they are really mature. Every system does have a problem with scaling past a certain point, but I think right now ion trapping has a viable path.”</p>
<p>Qubits need to be cheap and future-proof</p>
<p>Whereas the trapped-ion method requires elaborate tools—an electromagnetic field and lasers—to trap the ions, scientists are finding that Russian “magic diamonds” can hold qubits in place and thus act the same way that a trapped-ion rig does. By replacing a single carbon atom in a diamond’s atomic lattice with a nitrogen atom and leaving a neighboring lattice node empty, engineers can create what’s called a nitrogen-vacancy (NV) center. This is generally inexpensive since it’s derived from nature. The NV center is a flaw, or blemish, in an otherwise super-pure atomic structure.
“I like to think of the NV center as an inside-out atom, in a way,” Goldman says. In a typical atom, electrons surround the nucleus in orbitals; in this case, electrons occupy orbitals inside the vacancy of the NV center (they come from the valence, or outer-ring, electrons of the nitrogen atom) while the NV center’s electronic spins react with the nuclear spin of some of the carbon atoms nearby. In this case, both the NV center and the adjacent carbon atoms function as qubits, and the diamond lattice keeps them stationary and entangled.
These qubits—called solid-state spin qubits—are limited, though, since the system can only have as many qubits as there are neighboring carbon atoms (just three in the immediate vicinity). And NV centers are difficult to control, which means they might not be as scalable as other options. Nature, too, is fundamentally variable, and NV centers can be influenced by the nuclear spins of other atoms in the lattice—which means one diamond lattice is undoubtedly going to be slightly different from the next.</p>
<p>“In terms of being a general, perfect qubit, ions may be better suited… just because they’re cleaner,” Goldman says.</p>
<p>NV centers can operate at room temperature (trapped ions can, too), which is a massive bonus, depending on what scientists want to use them for. For example, we may need to experiment with types of quantum machines that aren’t large enough to maintain cool temperatures, or that need to accomplish tasks that wouldn’t be allowed in a standard ultra-cold arrangement.
Researchers at the Delft University of Technology in the Netherlands have entangled an NV center’s electronic spin with the spins of nine nearby nuclei, an impressive start to this burgeoning technology, which is being developed by a Harvard-bred start-up called Quantum Diamond Technologies.</p>

<p>Nicole Yunger Halpern, a theoretical physicist and quantum computing expert at Harvard University, says that NV centers are promising, but that the scientific community shouldn’t rule out other uses of solid-state qubits (qubits contained in solid objects). Ultimately, a mixture of qubit types in one system could be the best way to build a scalable quantum computer.
“Over the past decade or two, there have been revolutions in the way people have been using different types of platforms to build qubits,” she says. If scientists could figure out how to transfer information from one type of qubit to another, she says, they might be able to knit together a robust fabric of top-tier qubits.</p>
<p>Qubits need long coherence times</p>
<p>A popular type of qubit is the superconducting qubit, which has a decent coherence time, meaning it can endure in a state of quantum superposition for a relatively long time. These qubits take the form of superconducting (that is, zero electrical resistance) circuits that maintain a state of both 0 and 1 as a photon both does and doesn’t zoom through them. Though trapped ions have a better track record when it comes to coherence time, superconducting qubits (and NV centers) are close behind.</p>
<p>Some scientists, like Schoelkopf and the University of Chicago’s David Schuster, are trying to build a twist into this model that will help coherence times and improve this type of system. “When you’re using superconducting qubits in a quantum computer, you’re also using light that interacts with the superconducting qubits,” Yunger Halpern says. “Some of these groups are reversing the roles of the superconducting qubits and the light.” In other words, they’re storing quantum information in the light as opposed to the superconducting qubits.
Schoelkopf says this kind of information carrier can live longer than qubits created by conventional methods by a factor of 30 or 50. “Not just the rate but the number or type of errors that it can experience are smaller,” he says.</p>
<p>Qubits need to be flexible</p>
<p>Above all, the most refined and athletic qubits are the ones that are going to be more flexible. The ability to operate quantum computers at room temperature, for example, is a particularly enticing possibility that would give qubits more flexibility. And the more receptive qubits are to being guided by lasers, the more amenable they’ll be to entanglement.
“You want the qubits to be docile and go where they are led,” Yunger Halpern says. “This is maybe more of a characteristic of a show dog than an Olympic athlete.”
Techniques for adding flexibility to these systems vary tremendously: From understanding the relationship between entropy and information (which could affect how engineers understand thermodynamic processes in quantum situations) to using different methods of entanglement, scientists are training qubits to reach and surpass their expected limits.</p>

<p>This cat’s name is Qubit. He may not be an Olympic athlete, but the author thinks he’s a pretty Great Qubit. | Photo courtesy Amanda Gefter and Justin Smith
“There are always going to be physical challenges with a quantum computer,” says Ashley Montanaro, a quantum computation researcher at the University of Bristol. “But when you scale up, as long as the noise [that the qubits] have to contend with doesn’t increase too much, you’ll be able to have a system that’s a thousand or one million qubits.”
Scientists are slowly, incrementally making their way toward that goal. And in the process, these little qubits could help solve some universal puzzles.
“The transition from truly quantum behavior to behavior that can be described as classical mechanics has been mysterious for a long time,” Yunger Halpern says. “I hope that as our quantum systems grow, we’ll be able to use them more and more to probe the crossover.”
<h1><a href="https://news.cnrs.fr/articles/computers-promises-of-the-quantum-dawn">[Article 6]: Computers: Promises of the Quantum Dawn</a></h1>
Long a simple physicist's idea, the quantum computer, which promises to revolutionise computing, is increasingly becoming a tangible reality. The first machines able to surpass traditional computers should appear in a few years.
The world's most powerful supercomputers could soon be relegated to the prehistory of computing. For the most optimistic, the next few years will see the arrival of a new kind of machine known as quantum computer, offering phenomenal computing capacities. Imagined during the early 1980s by the winner of the Nobel Prize in physics, Richard Feynman, the concept of such a computer is today increasingly becoming a reality.  "We are currently experiencing a pivotal period in which industrial actors like Google and IBM have seized upon the subject, which had previously been the domain of research laboratories. This will help us overcome major technological issues," enthuses Tristan Meunier of the Institut Néel.1 It's the same story for Eleni Diamanti of the Laboratoire d'informatique de Paris 6.2 "In the coming years we will have quantum computers that perform well enough to beat traditional computers on certain problems."
The power of superposition and entanglement
As its name suggests, a quantum computer uses the laws of quantum mechanics, a theory that describes physical phenomena on the atomic scale. These striking laws allow a particle, such as an atom or a molecule, to be in different states at the same time—referred to as the superposition of states. On an ordinary computer, information is coded in the form of bits that can have one of only two values, 0 or 1, whereas quantum bits (or qubits) can simultaneously take the values of 0 and 1, depending on whether an electrical current passes through a transistor. What's more, when two qubits interact, their physical states are "entangled," such that the two systems can no longer be described independently, which is referred to as entangled states.</p>

<p>Nobel Prize winner Richard Feynman (1918-1988) during a conference at Cern in 1965.
 CERN / Science Photo Library / Cosmos
Share
Thanks to the phenomena of superposition and entanglement, a quantum computer can in theory have access to all of the possible results of a calculation in a single step, whereas a traditional computer would process the information consecutively, one result after another. It is this massive parallelism that is central to the quantum computer's power.
The computation speed of quantum algorithms
In the 1990s, researchers proposed algorithms for such computers, and mathematically demonstrated that when implemented on such machines, they would effectively perform certain calculations at speeds unimaginable using a classical computer. In 1994, the American mathematician Peter Shor of MIT presented an algorithm that could factorize any number, which is to say decompose it into a product of prime numbers, doing so in record time. 
This would be enough to break most of today's cryptographic systems, from the encryption of bank transactions to the coding used to exchange state secrets, which precisely rely on the tremendous amount of time it takes to calculate the factorization of increasingly large numbers. A problem of this kind, which would take a classical computer a few billion years, would be resolved by a quantum computer in a matter of minutes!
Similarly, in 1997, Lov Grover from Bell Labs demonstrated with his algorithm that a quantum computer could considerably increase the effectiveness of the classical algorithms used to search for information in a database. 
For example, the search for one item among ten thousand elements of data would only require approximately one hundred steps, as opposed to ten thousand for a traditional computer. The time it takes to process massive amounts of data would be considerably reduced, hence the interest of companies such as Google in this new technology.
The accumulation of qubits
What was left was to develop the building blocks of these quantum computers, the famous qubits, able to be in two states simultaneously. Physicists across the globe quickly got to work. Many candidates were tested, including atoms, ions, molecules, electrons, photons, and superconducting circuits. There have already been notable successes in the manipulation of these qubits. For example in 2003, Rainer Blatt from the University of Innsbruck in Austria created the first two-bit logic gate using calcium ions, a key device for performing operations through the coupling of qubits.</p>

<p>Superconducting circuit chip integrating 3 qubits (actual size: 8mm x 4mm).
 IBM Research
Share
As for the greatest calculation exploit, it was achieved in 2012 by a team at the University of Bristol in England, which successfully used a photonic device to factorize the number 21, which is to say to show that it breaks down into 3 times 7. The performance was of course modest, but it represents a demonstration of the principle of Shor's algorithm, whose power could be used for much larger numbers.
For as we have seen, the advantage of quantum calculation over its classical equivalent is all the greater if the quantity of information being processed is large. In other words, "in order to perform well and be of interest, a quantum computer must include a large number of qubits. For factorization problems, a thousand must be coupled at the very least," points out Simon Perdrix of the Laboratoire lorrain de recherche en informatique et ses applications.3
The obstacle of decoherence
And that is precisely the problem. "In order for a quantum computer to function, its qubits must keep these quantum properties during the calculation. Yet interactions with the environment (magnetic field, light, thermal agitation...) can all cause a quantum system to lose its properties. And this is all the more true given the number of qubits contained in the system," explains Sébastien Tanzilli of the Institut de physique de Nice,4 who is in charge of quantum technologies for the CNRS, and represents France within the Quantum Community Network, the committee tasked with steering the European initiative Quantum Technologies Flagship. This phenomenon, referred to as decoherence, represents the primary obstacle in the construction of these computers.
Yet far from being discouraged, physicists tried from the beginning to better understand the process, and did everything they could to control it. As a result, since the development of the first qubits nearly 25 years ago, their coherence time has continued to increase, and an ever-larger number of qubits have been successfully entangled. "Advances in the conception and manipulation of qubits have surely but slowly expanded the number of qubits, with nobody being able to say where this limit is located," observes Meunier.  Currently, the record number of entangled qubits is 20. It is true that in 2018 Google announced that it had produced a quantum processor made up of 72 qubits, but without demonstrating how many of them were effectively entangled.
Promising implementations
In this race for the greatest number of qubits and the creation of a quantum computer, two systems, currently neck and neck, offer the most interesting prospects. The first involves trapped ions. Developed in the early 1990s, these are atoms—especially calcium—that have had one or more electrons removed, and that are then trapped in a vacuum using lasers. They hold the record for coherence time, which has reached multiple minutes in certain devices. The disadvantage is that they are slow to manipulate, which slows down calculations. Another drawback is that "trapping techniques are relatively complicated to implement, such that it is difficult to see how it's possible to increase size and reach 1000 qubits," notes Tanzilli. Some have already imagined solutions for doing so, although this remains a major challenge.
The second favourite is superconducting circuits.  These micrometric-sized electrical circuits appeared in the late 1990s, and include metallic electrodes that become superconducting—which is to say they conduct electricity without resistance—at very low temperature. Thanks to ultra-thin barriers between these electrodes, known as Josephson junctions, these circuits behave like artificial atoms whose quantum state can be manipulated.  With regard to decoherence, superconducting qubits are less effective than trapped ions, but they are faster to manipulate. 
For Patrice Bertet of the Service de physique de l’état condensé au CEA Saclay,5 the laboratory that played a pioneering role in the development of these systems, they offer an additional advantage: "The production technique is fairly simple, which makes it easy to duplicate and integrate a large number of them on the same chip." It explains why these devices are so popular with industry. IBM and Google notably chose this option for their machines.</p>

<p>Internal view of the dilation refrigerator of a quantum computer with superconducting circuits.
 IBM Research
Share
More recently, a third outsider has joined the race, namely electron spins in silicon, which involve isolating electrons in a silicon matrix and using their spin—or the particle's rotation around itself—as a quantum bit of information. Developed over the last five years, these qubits are still relatively "fragile," and only two of them have been successfully entangled to date. However, it is generally agreed that they will soon achieve the same levels of performance as the two pioneering devices. In particular, "they are the only ones that can be integrated on a very large scale. Their production uses exactly the same techniques as those of micro and nanoelectronics, which we have a good command of, and subsequently enables their extreme miniaturization," Meunier adds. He is enthusiastic about this technology's potential, and is one of the leaders of the QuCube project being conducted in partnership with two other laboratories,6 whose objective is to develop a silicon-based processor that includes 100 qubits within the next six years.</p>

<p>White room of l'Institut Néel: the beam of a scanning electron microscope allows for the production and study of circuits dedicated to fundamental physics or quantum computing.
 C. Frésillon/Institut Néel/CNRS Photothèque
Share
So which of these three candidates will win out, and lead to the creation of the first quantum computer? "It's impossible to say, as each device offers certain advantages that the others do not have. None of them can today presume to come out on top," believes Tanzilli.
Essential error correction
One thing is certain, and that is improving qubit performance will not be enough. To make the quantum computer a reality, it is also important to correct calculation errors resulting from decoherence. Mathematicians and computer scientists quickly understood this, and developed correcting codes, the quantum equivalent of the error-correcting algorithms used in our computers. It has even been demonstrated that in theory, if a qubit's error rate is below a certain value, it is possible to correct errors faster than they occur. "The idea of correcting codes was a small revolution in the field. Even the most pessimistic began to believe in the possibility of a quantum computer," admits Tanzilli.</p>

<h3>Prototype of the 16-qubit quantum processor produced by IBM.</h3>
 <p>IBM Research
Share
The principle of correcting codes is simple. They use a group of multiple "physical" qubits to code the information of a single "logical" qubit. By measuring the properties of physical qubits, we can determine—thanks to entanglement—whether the logical qubit is no longer in the desired state, and correct it immediately. However, their implementation is more complicated in practice, as it is believed that it would take 1,000—and even 10,000—physical qubits for each logical qubit that can be used for calculation. In other words, the ideal quantum computer should include not just a few thousand qubits, but a few million! "The manipulation and control of such a large number of qubits remains largely beyond reach," warns Patrice Bertet. This has not prevented physicists from testing these methods on a small number of qubits.
Eleni Diamanti recognizes that a theoretical breakthrough is needed to increase the performance of these codes and reduce the number of qubits they require. "Only then will we have a quantum computer worthy of the name. Computer scientists, mathematicians, and physicists are working on this together, and I am convinced that they will one day solve this problem."
Toward quantum micro-calculators?
Not everyone wants to wait for the emergence of these universal quantum computers, which when equipped with the best qubits and high-performance correcting codes, will be able to perform any complex calculation. "The current trend, which has led to an enormous amount of research, is to identify which problems, using which algorithms, can be solved by near-term computers with fewer qubits and no error-correcting system," notes Iordanis Kerenidis, of l’Institut de recherche en informatique fondamentale,7 and director of the Paris Centre for Quantum Computing.
The first step toward this objective will be to demonstrate quantum supremacy, in other words to experimentally prove for a given algorithm the advantage of the quantum over the classic. Specialists believe that this milestone should be achieved in just five years, with the appearance of small quantum calculators containing 50 to 100 qubits. Researchers are preparing for this, and have already identified a type of mathematical problem—probability distribution calculations—that lends itself to such a demonstration. "Its resolution will certainly not be of practical utility, but it will launch the use of quantum machines for problems that are worthy of interest," posits Kerenidis.
From quantum calculation to simulation
The fields of chemistry and materials science should be the first to benefit. There are predictions that with machines of a hundred qubits, the synthesis of new molecules or the development of materials with unprecedented properties will be largely accelerated. How? By using quantum computers for simulation rather than calculation. The idea, which was originally suggested by Richard Feynman, is to imitate complex physical systems (molecules, materials, etc.) with the help of simpler artificial quantum systems, namely qubits. By varying parameters at will (distance of atoms, force of interactions...), which are not adjustable in real systems, we can model their dynamics and thereby understand them better.
Quantum simulation has already yielded results, but with a greater number of qubits it promises even more spectacular advances. "The advantage of simulation is that decoherence is ultimately no longer an enemy, because the systems that are simulated are themselves subject to this phenomenon. Thus there is no need to have perfect quantum computers," stresses Simon Perdrix. 
With computers of a few hundred qubits, numerous other applications could be created. Firstly, optimization tasks could be made much more efficient thanks to quantum calculation, with numerous sectors standing to benefit, from the management of road traffic to energy transportation networking and financial prediction.
A revolution for machine learning?
The acceleration of calculation speed would also have major repercussions in machine learning, a very fashionable technique in artificial intelligence that is used to analyse and sort data in very large digital databases. Once again there will be numerous applications ranging from improved web search engines to much more precise medical diagnostics, to cite just two. "In both optimization and machine learning, we are searching not for exact solutions, but to provide answers that are satisfactory. We can therefore tolerate errors much more than in a factorization problem, for example. That is why the use of even near-term quantum computers will contribute so much," emphasizes Kerenidis.</p>

<h3>Internal view of the Q quantum computer by IBM.</h3>
 IBM Research
Share
<p>It is not by chance that the field of quantum algorithmics has never been as active as it is today. A single example: in 2017, Kerenidis presented a machine learning algorithm that can, in theory, recommend films, books, or matches that are exponentially more effective than using current methods. Who knows when an actual quantum computer will be created, and whether it will indeed become a reality, but along the path toward its creation, the prospects for the average person are extremely tantalizing.</p>




<h1><a href="https://m.phys.org/news/2019-06-path-reliable-quantum.html">[Article 7]: Researchers demonstrate new path to reliable quantum computation</a></h1>
<p>Researchers at the University of Chicago published a novel technique for improving the reliability of quantum computers by accessing higher energy levels than traditionally considered. Most prior work in quantum computation deals with "qubits," the quantum analogue of binary bits that encode either zero or one. The new work instead leverages "qutrits," quantum analogues of three-level trits capable of representing zero, one or two. The UChicago group worked alongside researchers based at Duke University. Both groups are part of the EPiQC (Enabling Practical-scale Quantum Computation) collaboration, an NSF Expedition in Computing. EPiQC's interdisciplinary research spans from algorithm and software development to architecture and hardware design, with the ultimate goal of more quickly realizing the enormous potential of quantum computing for scientific discovery and computing innovation.</p>
<p>Accessing higher energy levels</p>
<p>The work can be viewed in the context of a fundamental space-time trade-off that is common in computer science: Programs can be sped up by using more memory, or alternatively, programs can reduce memory requirements by incurring longer runtimes. But in the context of quantum computing, where near-term machines are severely constrained in both memory and runtimes supported, neither of these tradeoffs are acceptable.
The solution the EPiQC team discovered was to break the abstraction of using binary qubits. "While binary logic makes sense for the on-off physics underlying conventional computers, quantum hardware is not inherently binary," explains researcher Pranav Gokhale, a graduate student at the University of Chicago. In fact, states on a quantum computerbelong to an infinite spectrum, so the qubit is merely an artificially engineered choice of using only two of the states.
The team found that by allowing the use of three states via qutrits, one of the fundamental operations in quantum computation is exponentially faster without requiring additional memory. The team verified their discovery with simulations run under realistic noise conditions.
"Qutrits do come at a cost, since the presence of an additional state implies more possible sources of error," said Gokhale. "Nonetheless, our simulations demonstrate that qutrits have a convincing advantage with two to ten times higher reliability than qubit-only algorithms for near-term benchmarks."
The team's discovery is well matched to EPiQC's interdisciplinary focus on bridging the gap between quantum hardware and software. An early stage of this work was presented at the Quantum Information Processing Conference this January, where it won the award for best poster. Since then, the research has been fine-tuned to match sophisticated hardware models developed in conjunction with experts working on superconducting and trapped ion quantum computers.
"By tailoring algorithms to take advantage of the unique capabilities of quantum hardware, we realize efficiency gains that are otherwise hidden behind the abstraction barriers between hardware and software," notes Fred Chong, Seymour Goodman Professor of Computer Science at UChicago and lead PI for EPiQC. "In this case, our hardware modeling led us to revisit and challenge the conventional wisdom that binary operation is best for computation."
The full paper, "Asymptotic Improvements to Quantum Circuits via Qutrits," is now published on arXiv.</p>


<h2>LINKS</h2>
<ul>
<li><a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/quantum-computing-google-computer-lab-hartmut-neven-law-a8973951.html">https://www.independent.co.uk/life-style/gadgets-and-tech/news/quantum-computing-google-computer-lab-hartmut-neven-law-a8973951.html</a></li> 
<li><a href="https://venturebeat.com/2019/06/26/d-waves-open-source-platform-for-quantum-classical-hybrid-apps-hits-general-availability/">https://venturebeat.com/2019/06/26/d-waves-open-source-platform-for-quantum-classical-hybrid-apps-hits-general-availability/</a></li>
<li><a href="https://www.pbs.org/wgbh/nova/video/six-ways-quantum-computers-could-change-the-world/">https://www.pbs.org/wgbh/nova/video/six-ways-quantum-computers-could-change-the-world/</a></li>
<li><a href="https://interestingengineering.com/googles-quantum-processor-may-achieve-quantum-supremacy-in-months">https://interestingengineering.com/googles-quantum-processor-may-achieve-quantum-supremacy-in-months</a></li>
<li><a href="https://news.cnrs.fr/articles/computers-promises-of-the-quantum-dawn">https://news.cnrs.fr/articles/computers-promises-of-the-quantum-dawn</a></li>
<li><a href="https://m.phys.org/news/2019-06-path-reliable-quantum.html">https://m.phys.org/news/2019-06-path-reliable-quantum.html</a></li>
<li><a href="http://www.iamwire.com/2019/06/need-promise-reality-quantum-computing/183286">http://www.iamwire.com/2019/06/need-promise-reality-quantum-computing/183286</a></li>
</ul>
</div>
</body>
</html>
